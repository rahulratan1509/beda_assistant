# ğŸ¤– Beda Assistant

**Beda Assistant** is a ChatGPT-style local AI assistant powered by open-source LLMs (like LLaMA-3.2), featuring smart web search with citation-style answers, full-page scraping fallback, and token-by-token response streaming. Built with a custom Gradio UI and session-aware memory.

---

## âœ¨ Features

- âœ… Local LLM support (LLaMA 3, OpenChat, etc.)
- ğŸ” Web search via Google (SerpAPI) + DuckDuckGo fallback
- ğŸ“š LLM-powered answer summarization with citations like [1], [2]
- ğŸ“° Auto full-page scraping with `newspaper3k` for short snippets
- ğŸ§  Smart LLM-based decision to trigger search
- ğŸ§µ Token-by-token streaming responses (like ChatGPT)
- ğŸ—ƒï¸ Memory & session support
- ğŸ›ï¸ Toggle between auto/manual search mode
- ğŸ§° Modular and extensible Python architecture

---

## ğŸ“ Folder Structure

beda_assistant/
â”œâ”€â”€ .env # API keys and flags
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ main.py # Entry point
â”œâ”€â”€ run_beda.bat # Windows launcher
â”œâ”€â”€ push_changes.bat # Git helper
â”œâ”€â”€ generate_file_structure.py
â”œâ”€â”€ project_structure.txt # Generated structure summary
â”œâ”€â”€ data/ # Logs, sessions, memory files
â”œâ”€â”€ modules/
â”‚ â”œâ”€â”€ responder.py # LLM + search + summarizer
â”‚ â”œâ”€â”€ web_search.py # Google/DDG + scraping
â”‚ â”œâ”€â”€ session_manager.py # Chat history & memory
â”‚ â””â”€â”€ llm_wrapper.py # Local model wrapper
â”œâ”€â”€ ui/
â”‚ â””â”€â”€ interface.py # Gradio-based custom UI


---

## âš™ï¸ Setup Instructions

### 1. Clone the repo

git clone https://github.com/your-username/beda_assistant.git
cd beda_assistant



### 2. Install dependencies

pip install -r requirements.txt



> âœ… Python 3.10+ recommended

### 3. Add `.env` file

Create a `.env` file with:

SERPAPI_KEY=your_actual_key_here
ENABLE_WEB_SEARCH=true


### 4. Start the assistant

python main.py


Or on Windows:

run_beda.bat



---

## ğŸ” Web Search Modes

| Mode     | Description                                  |
|----------|----------------------------------------------|
| Auto     | LLM decides when to perform web search       |
| Manual   | Use `search:` prefix to force search         |
| Fallback | DuckDuckGo used if Google fails              |
| Scraping | Uses `newspaper3k` if snippet is too short   |

---

## ğŸ§  Compatible LLMs

Runs with any OpenAI-compatible local model server:

http://127.0.0.1:1234/v1/chat/completions



Examples:
- llama-3.2-1b-instruct
- openchat-3.5
- Mistral / Zephyr etc. via OAI-compatible API

---

## ğŸ“ Example Prompts

Tell me the latest news in space exploration.

or force search:
search: top universities for AI research 2025


Sample output:

> MIT and Stanford continue leading in AI research, with ETH Zurich and CMU climbing global ranks [1][2].

---

## ğŸ“ Git Ignore Tips

To track the `data/` directory, update your `.gitignore` like this:

Track data folder
!data/

makefile


Then:

git add -f data/
git commit -m "Track data folder"


---

## ğŸ› ï¸ Dev Notes

- Google search via SerpAPI (optional API key)
- DuckDuckGo fallback if SerpAPI fails or limit hits
- Scraping enabled when snippet is short (< 50 chars)
- Token streaming powered by Gradio with `stream=True`

---

## ğŸ§¾ License

MIT License â€” free for personal or commercial use.

---

## ğŸ™ Acknowledgements

- Meta AI (LLaMA)
- SerpAPI
- Gradio
- Newspaper3k

> Built with â¤ï¸ to be your personal, offline ChatGPT.
